{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow_datasets as tfds \n",
    "import os\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.layers import Dense, Layer, Conv2D, MaxPool2D,GlobalAveragePooling2D,BatchNormalization\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'aircraft carrier', b'airplane', b'alarm clock', b'ambulance', b'angel', b'animal migration', b'ant', b'anvil', b'apple', b'arm']\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "categories = [line.rstrip(b'\\n') for line in urllib.request.urlopen('https://raw.githubusercontent.com/googlecreativelab/quickdraw-dataset/master/categories.txt')]\n",
    "print(categories[:10])\n",
    "category = 'candle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141545 images to train on\n",
      "2000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Creates a folder to download the original drawings into.\n",
    "# We chose to use the numpy format : 1x784 pixel vectors, with values going from 0 (white) to 255 (black). We reshape them later to 28x28 grids and normalize the pixel intensity to [-1, 1]\n",
    "\n",
    "if not os.path.isdir('npy_files'):\n",
    "    os.mkdir('npy_files')\n",
    "    \n",
    "url = f'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/{category}.npy'  \n",
    "urllib.request.urlretrieve(url, f'npy_files/{category}.npy')\n",
    "\n",
    "images = np.load(f'npy_files/{category}.npy')\n",
    "print(f'{len(images)} images to train on')\n",
    "\n",
    "# You can limit the amount of images you use for training by setting :\n",
    "train_images = images[:10000]\n",
    "# You should also define a samller subset of the images for testing..\n",
    "# TODO\n",
    "test_images = images[10000:12000]\n",
    "print(len(test_images))\n",
    "print(len(train_images))\n",
    "# Notice that this to numpy format contains 1x784 pixel vectors, with values going from 0 (white) to 255 (black). We reshape them later to 28x28 grids and normalize the pixel intensity to [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define shuffle and batching sizes\n",
    "batch_size = 32\n",
    "shuffle_size = 1000\n",
    "prefetch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    # change dtype to float32\n",
    "    data = data.map(lambda img: tf.cast(img, tf.float32))\n",
    "    # change value range from 0-255 to -1 - 1\n",
    "    data = data.map(lambda img: (img/128)-1) \n",
    "    # change format to 28,28,1\n",
    "    data = data.map(lambda img: tf.reshape(img, (28,28,1)))\n",
    "    # do other prepocessing stuff\n",
    "    data = data.shuffle(shuffle_size).batch(batch_size).prefetch(prefetch_size)\n",
    "    return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-13 16:07:02.099529: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-13 16:07:02.099623: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# create datasets from tensor\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(train_images)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(test_images)\n",
    "\n",
    "train_ds = preprocess(train_ds)\n",
    "test_ds = preprocess(test_ds)\n",
    "\n",
    "#check data format real quick\n",
    "# for x in test_ds:\n",
    "#     print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.conv1 = Conv2D(32,kernel_size=2, padding='same')\n",
    "        self.conv2 = Conv2D(32, kernel_size=3, padding='same')\n",
    "        self.batch1 = BatchNormalization()\n",
    "\n",
    "        self.conv3 = Conv2D(32, kernel_size=2, padding='same')\n",
    "        self.conv4 = Conv2D(32, kernel_size=2, padding='same')\n",
    "        self.batch2 = BatchNormalization()\n",
    "\n",
    "        self.out = Dense(1, activation='sigmoid')\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, input):\n",
    "        x = self.conv1(input)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch1(x)\n",
    "        x = self.conv3(input)\n",
    "        x = self.conv4(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.out(x)\n",
    "        return x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d6ce7daced66c1b43e67ee1266804bcc56425fa4e39cc8300d2c0d41d8b5ef83"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ann': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
