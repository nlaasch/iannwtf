{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Optimisation Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHUFFLE_BUFFER = 500\n",
    "BATCH_SIZE = 20\n",
    "PREFETCH_SIZE = 20\n",
    "\n",
    "cpu_count = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Binary Function\n",
    "Returns True if the target quality is higher than the entire dataset quality mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default threshold everything above 5 is good \n",
    "def make_binary(target, threshold = 5):\n",
    "  return int(target > threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What keys are there and what should be input and target for our NN\n",
    "#### Inputs\n",
    "fixed acidity    \n",
    "volatile acidity       \n",
    "citric acid       \n",
    "residual sugar       \n",
    "chlorides       \n",
    "free sulfur dioxide       \n",
    "total sulfur dioxide       \n",
    "density       \n",
    "pH       \n",
    "sulphates       \n",
    "alcohol       \n",
    "\n",
    "#### Target\n",
    "quality     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "csv_file = tf.keras.utils.get_file('winequality-red.csv', 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed acidity           float64\n",
      "volatile acidity        float64\n",
      "citric acid             float64\n",
      "residual sugar          float64\n",
      "chlorides               float64\n",
      "free sulfur dioxide     float64\n",
      "total sulfur dioxide    float64\n",
      "density                 float64\n",
      "pH                      float64\n",
      "sulphates               float64\n",
      "alcohol                 float64\n",
      "quality                   int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert CSV to Tensorflow with pandas\n",
    "df = pd.read_csv(csv_file, sep = ';')\n",
    "print(df.dtypes)\n",
    "\n",
    "#tf.convert_to_tensor(df)\n",
    "\n",
    "df_target = df['quality']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset and pipe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "full_size = len(df)\n",
    "\n",
    "train_size = int(0.7 * full_size)\n",
    "valid_size = int(0.15 * full_size)\n",
    "\n",
    "train_ds, valid_ds, test_ds = \\\n",
    "              np.split(df.sample(frac=1, random_state=42), \n",
    "                       [train_size,train_size + valid_size])\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate lables from input\n",
    "train_label = train_ds[\"quality\"]\n",
    "train_input = train_ds.drop(\"quality\", axis = 1)\n",
    "\n",
    "test_label = test_ds[\"quality\"]\n",
    "test_input = test_ds.drop(\"quality\", axis = 1)\n",
    "\n",
    "validate_label = valid_ds[\"quality\"]\n",
    "validate_input = valid_ds.drop(\"quality\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build tensorflow dataset\n",
    "train_ds =tf.data.Dataset.from_tensor_slices((train_input, train_label))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_input, test_label))\n",
    "valid_ds = tf.data.Dataset.from_tensor_slices((validate_input, validate_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(dataset):\n",
    "  dataset = dataset.map(lambda inputs , target: (inputs, make_binary(target)))\n",
    "  dataset = dataset.batch(BATCH_SIZE).prefetch(PREFETCH_SIZE)\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = prepare_data(train_ds)\n",
    "test_ds = prepare_data(test_ds)\n",
    "valid_ds = prepare_data(valid_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom layer\n",
    "\n",
    "class CustomLayer(tf.keras.layers.Layer):\n",
    "    # init func with customizable size and activation function, standard units=8, Activation = sigmoid\n",
    "    def __init__(self, units=8, activation=tf.nn.sigmoid):\n",
    "        super(CustomLayer, self).__init__()\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "        \n",
    "    # build function to apply shape of input to layer when build, creating according weights and biases \n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                initializer='random_normal',\n",
    "                                trainable=True)\n",
    "\n",
    "        self.b = self.add_weight(shape=(self.units,), \n",
    "                              initializer='random_normal',\n",
    "                              trainable=True)\n",
    "    # when called return neuron output/drive by multiplying input with weights + bias and applying the activation function\n",
    "    def call(self, inputs):\n",
    "        x = tf.matmul(inputs, self.w) + self.b\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom model with custom layer\n",
    "class CustomModel(tf.keras.Model):\n",
    "    \n",
    "    # \n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.layer1 = CustomLayer(64) # sigmoid is standard\n",
    "        self.layer2 = CustomLayer(256) # Use 256 as its the first amount where the accuracy gets over 0.5\n",
    "        self.out = CustomLayer(1)\n",
    "    \n",
    "    # cast the call-function as tf.function to increase efficiency\n",
    "    @tf.function\n",
    "    # pass the input through the layers of the network and return the output\n",
    "    def call(self, inputs):\n",
    "        x = self.layer1(inputs)\n",
    "        x = self.layer2(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the loss of an input for the model and optimize/tweak according the parameters\n",
    "def train_step(model, input, target, loss_function, optimizer):\n",
    "    # use tf.gradientTape to compute loss, then gradients and apply these to the model to modify the parameters\n",
    "    with tf.GradientTape() as tape:\n",
    "        prediction = model(input)\n",
    "        loss = loss_function(target, prediction)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "\n",
    "# compute the differences between or model prediction and the label, -> Supervision\n",
    "def test(model, test_data, loss_function):\n",
    "  # test over complete test data\n",
    "  test_accuracy_aggregator = []\n",
    "  test_loss_aggregator = []\n",
    "\n",
    "  for (input, target) in test_data:\n",
    "    prediction = model(input)\n",
    "    sample_test_loss = loss_function(target, prediction)\n",
    "    sample_test_accuracy =  np.round(target, 0) == np.round(prediction, 0)\n",
    "    sample_test_accuracy = np.mean(sample_test_accuracy)\n",
    "    test_loss_aggregator.append(sample_test_loss.numpy())\n",
    "    test_accuracy_aggregator.append(np.mean(sample_test_accuracy))\n",
    "    \n",
    "# for all input and computed losses get the mean of accuracy and loss and return them\n",
    "  test_loss = tf.reduce_mean(test_loss_aggregator)\n",
    "  test_accuracy = tf.reduce_mean(test_accuracy_aggregator)\n",
    "\n",
    "  return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: ((None, 11), (None,)), types: (tf.float64, tf.int32)>\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Exception encountered when calling layer \"custom_model\" (type CustomModel).\n\n Attempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[node custom_layer/MatMul\n (defined at <ipython-input-11-34c1eb9b10b4>:21)\n]] [Op:__inference_call_513]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node custom_layer/MatMul:\nIn[0] inputs (defined at C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:92)\t\nIn[1] custom_layer/MatMul/ReadVariableOp:\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelapp.py\", line 619, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\asyncio\\events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\gen.py\", line 814, in inner\n>>>     self.ctx_run(self.run)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\gen.py\", line 775, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 358, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 261, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 536, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\ipkernel.py\", line 302, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\zmqshell.py\", line 539, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2898, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2944, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3169, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-45-78d0284cb41f>\", line 22, in <module>\n>>>     test_loss, test_accuracy = test(model, test_ds, cross_entropy_loss)\n>>> \n>>>   File \"<ipython-input-44-f736eaacfa6f>\", line 19, in test\n>>>     prediction = model(input)\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"<ipython-input-12-4325a7677600>\", line 15, in call\n>>>     x = self.layer1(inputs)\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"<ipython-input-11-34c1eb9b10b4>\", line 21, in call\n>>>     x = tf.matmul(inputs, self.w) + self.b\n>>> \n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(20, 11), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-78d0284cb41f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# get initial accuracy- and loss valus before training starts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mtest_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mtest_accuracies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-f736eaacfa6f>\u001b[0m in \u001b[0;36mtest\u001b[1;34m(model, test_data, loss_function)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0msample_test_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0msample_test_accuracy\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Exception encountered when calling layer \"custom_model\" (type CustomModel).\n\n Attempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[node custom_layer/MatMul\n (defined at <ipython-input-11-34c1eb9b10b4>:21)\n]] [Op:__inference_call_513]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node custom_layer/MatMul:\nIn[0] inputs (defined at C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:92)\t\nIn[1] custom_layer/MatMul/ReadVariableOp:\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelapp.py\", line 619, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\asyncio\\events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\gen.py\", line 814, in inner\n>>>     self.ctx_run(self.run)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\gen.py\", line 775, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 358, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 261, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 536, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\ipkernel.py\", line 302, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\zmqshell.py\", line 539, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2898, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2944, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3169, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-45-78d0284cb41f>\", line 22, in <module>\n>>>     test_loss, test_accuracy = test(model, test_ds, cross_entropy_loss)\n>>> \n>>>   File \"<ipython-input-44-f736eaacfa6f>\", line 19, in test\n>>>     prediction = model(input)\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"<ipython-input-12-4325a7677600>\", line 15, in call\n>>>     x = self.layer1(inputs)\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"<ipython-input-11-34c1eb9b10b4>\", line 21, in call\n>>>     x = tf.matmul(inputs, self.w) + self.b\n>>> \n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(20, 11), dtype=float32)"
     ]
    }
   ],
   "source": [
    "print(train_ds)\n",
    "\n",
    "\n",
    "\n",
    "#predefine learning-rate and epochs\n",
    "num_epochs = 10\n",
    "alpha = 0.1\n",
    "\n",
    "# create a model\n",
    "model = CustomModel()\n",
    "\n",
    "# define loss-function and optimizer\n",
    "cross_entropy_loss = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer = tf.keras.optimizers.SGD(alpha)\n",
    "\n",
    "# create empty arrays to store test/accuracy values, to track the network progress\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "# get initial accuracy- and loss valus before training starts\n",
    "test_loss, test_accuracy = test(model, test_ds, cross_entropy_loss)\n",
    "test_losses.append(test_loss)\n",
    "test_accuracies.append(test_accuracy)\n",
    "\n",
    "train_loss, _ = test(model, train_ds, cross_entropy_loss)\n",
    "train_losses.append(train_loss)\n",
    "\n",
    "\n",
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # print accuracy of each epoch\n",
    "    print(f'Epoch: {str(epoch)} starting with accuracy {str(test_accuracies[-1])}')\n",
    "    \n",
    "    loss_epoch = []\n",
    "    # for all input, do a forwardstep and obtain loss\n",
    "    for input, target in train_ds:\n",
    "        train_loss = train_step(model, input, target, cross_entropy_loss, optimizer)\n",
    "        loss_epoch.append(train_loss)\n",
    "    # get the mean loss of this epoch by using reduce_sum of TF over all input-losses and appending to the array  \n",
    "    train_losses.append(tf.reduce_mean(loss_epoch))\n",
    "    \n",
    "    # get the losses and accuracy of this epoch and store them\n",
    "    test_loss, test_accuracy = test(model, test_ds, cross_entropy_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    \n",
    "# print accuracy after 10 epochs\n",
    "print(test_accuracies[-1])\n",
    "          \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-b445af62ff04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mline1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mline2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_losses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mline3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_accuracies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training steps\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "line1, = plt.plot(train_losses)\n",
    "line2, = plt.plot(test_losses)\n",
    "line3, = plt.plot(test_accuracies)\n",
    "plt.xlabel(\"Training steps\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend((line1,line2,line3),(\"training\",\"test\", \"accuracy\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b9830ad35c5e1e478e72d3dba1fdabe0ae743fb30b43ec349dcb945c2e8fc1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
