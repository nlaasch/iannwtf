{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import initializers, Model\n",
    "from tensorflow.keras.layers import Dense, Layer, Conv2DTranspose, MaxPooling2D, Conv2D, GlobalAveragePooling2D, Reshape\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whats open: #\n",
    "1. ''' ADD PROPER DATA & Accuracy '''\n",
    "2. Problem with input shape / Network architecture\n",
    "2. Plotting of bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "VERBOSE = True\n",
    "SHUFFLE_SIZE = 1000\n",
    "BATCH_SIZE = 32\n",
    "PREFETCH_SIZE = 64\n",
    "BUFFER_SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds = tfds.load('mnist', split=['train','test'], as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "# X_train = X_train.astype('float32')\n",
    "# X_test = X_test.astype('float32')\n",
    "# X_train /= 255\n",
    "# X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(images, noise_factor = 0.1, noise_func = \"normal\"):\n",
    "    if noise_func == \"gaussian\":\n",
    "        sample_noise = keras.layers.GaussianNoise(noise_factor, dtype=tf.float32)\n",
    "        noisy = sample_noise(images, training = True)\n",
    "    elif noise_func == \"normal\":\n",
    "        noisy = images + noise_factor * tf.random.normal(shape = images.shape)\n",
    "        noisy = tf.clip_by_value(noisy, clip_value_min = 0., clip_value_max = 1.)\n",
    "    return noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.autograph.experimental.do_not_convert\n",
    "def preprocess(data, noise_factor = 0.2, prepare = True):\n",
    "    # Cast Image pixel values as floats\n",
    "    data = data.map(lambda img, target: (tf.cast(img, tf.float32), target))\n",
    "    # Normalize pixel values\n",
    "    data = data.map(lambda img, target: ((img/255), target))\n",
    "    # Add noise to the data\n",
    "    data = data.map(lambda img, target: (add_noise(img, noise_factor = noise_factor), img)) # image as normalized vector  \n",
    "    # Apply OneHot to picture labels\n",
    "    #data = data.map(lambda img, target: (img, tf.one_hot(target, 10)))\n",
    "    # Shuffle, batch and prefetch\n",
    "    # data = data.map(lambda img, target: (img.reshape(-1, 28, 28, 1), target))\n",
    "    # data = data.map(lambda img, target: (tf.reshape(img, (-1, 28, 28, 1)), target))\n",
    "    if prepare: data = data.shuffle(SHUFFLE_SIZE).batch(BATCH_SIZE).prefetch(PREFETCH_SIZE)\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 16:02:07.801527: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds_image = preprocess(train_ds, noise_factor = 0.2, prepare = False)\n",
    "train_ds_noisy = preprocess(train_ds)\n",
    "test_ds_noisy = preprocess(test_ds)\n",
    "\n",
    "for image, label in train_ds_image.take(1):\n",
    "  plt.imshow(label)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Layer):\n",
    "  def __init__(self):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.conv_1 = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\") # 32 layers of flitered 28x28 features\n",
    "    self.pool_1 = MaxPooling2D((2, 2), padding=\"same\") # 32 / 14 / 14 \n",
    "    self.conv_2 = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\") # 32 / 14 / 14\n",
    "    self.pool_2 = MaxPooling2D((2, 2), padding=\"same\") # 32 / 7 / 7\n",
    "    self.global_pooling = GlobalAveragePooling2D()\n",
    "    self.dense = Dense(7, activation = \"relu\")\n",
    "\n",
    "  def call(self, input):\n",
    "    x = self.conv_1(input)\n",
    "    x = self.pool_1(x)\n",
    "    x = self.conv_2(x)\n",
    "    x = self.pool_1(x)\n",
    "    x = self.global_pooling(x)\n",
    "    x = self.dense(x)\n",
    "\n",
    "    return (x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(Layer):\n",
    "  def __init__(self):\n",
    "    super(Decoder, self).__init__()\n",
    "    # In Question\n",
    "    self.dense = Dense(49, activation = \"relu\")\n",
    "    # reshaoping layer to 7x7x1\n",
    "    self.reshaping_layer = Reshape((7,7,1))\n",
    "    self.transp_1 = Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")\n",
    "    self.transp_2 = Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")\n",
    "    self.conv_1 = Conv2D(1, (3, 3), activation=\"sigmoid\", padding=\"same\")\n",
    "\n",
    "  def call(self, input):\n",
    "    x = self.dense(input)\n",
    "    x = self.reshaping_layer(x)\n",
    "    x = self.transp_1(x)\n",
    "    x = self.transp_2(x)\n",
    "    x = self.conv_1(x)\n",
    "\n",
    "    return (x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(Model):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def call(self, input):\n",
    "        x = self.encoder(input)\n",
    "        x = self.decoder(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class Autoencoder():\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train step & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the loss of an input for the model and optimize/tweak according the parameters\n",
    "def train_step(model, input, target, loss_function, optimizer):\n",
    "    # use tf.gradientTape to compute loss, then gradients and apply these to the model to modify the parameters\n",
    "    with tf.GradientTape() as tape:\n",
    "        prediction = model(input)\n",
    "        loss = loss_function(target, prediction)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "\n",
    "# compute the differences between or model prediction and the label, -> Supervision\n",
    "def test(model, test_data, loss_function):\n",
    "  # test over complete test data\n",
    "  #test_accuracy_aggregator = []\n",
    "  test_loss_aggregator = []\n",
    "\n",
    "  for (input, target) in test_data:\n",
    "\n",
    "    prediction = model(input)\n",
    "    \n",
    "    sample_test_loss = loss_function(target, prediction)\n",
    "    #sample_test_accuracy =  np.argmax(target, axis=1) == np.argmax(prediction, axis=1)\n",
    "    \n",
    "    #sample_test_accuracy = np.mean(sample_test_accuracy)\n",
    "    test_loss_aggregator.append(sample_test_loss.numpy())\n",
    "    #test_accuracy_aggregator.append(np.mean(sample_test_accuracy))\n",
    "    \n",
    "# for all input and computed losses get the mean of accuracy and loss and return them\n",
    "  test_loss = tf.reduce_mean(test_loss_aggregator)\n",
    "  #test_accuracy = tf.reduce_mean(test_accuracy_aggregator)\n",
    "\n",
    "  return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training ResNet: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:36<00:00, 50.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 39.35226774215698\n",
      "Loss for this epoch: tf.Tensor(0.2544387, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:37<00:00, 49.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 40.52670216560364\n",
      "Loss for this epoch: tf.Tensor(0.24869914, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:35<00:00, 52.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 38.58087420463562\n",
      "Loss for this epoch: tf.Tensor(0.24398498, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:35<00:00, 52.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 38.55897903442383\n",
      "Loss for this epoch: tf.Tensor(0.23969081, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:37<00:00, 49.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 40.51921319961548\n",
      "Loss for this epoch: tf.Tensor(0.23417132, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:36<00:00, 51.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 39.646909952163696\n",
      "Loss for this epoch: tf.Tensor(0.22968227, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:37<00:00, 50.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 40.03547477722168\n",
      "Loss for this epoch: tf.Tensor(0.22553247, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:36<00:00, 51.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 38.984867095947266\n",
      "Loss for this epoch: tf.Tensor(0.22129528, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:38<00:00, 49.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 40.96799898147583\n",
      "Loss for this epoch: tf.Tensor(0.2196878, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:39<00:00, 47.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 42.351237297058105\n",
      "Loss for this epoch: tf.Tensor(0.21698032, shape=(), dtype=float32)\n",
      "Mean Time per Epoch: 39.95! With Parameters: \n",
      "Batch size: 32  Prefetch size: 64  Buffer size: 256\n"
     ]
    }
   ],
   "source": [
    "#predefine learning-rate and epochs\n",
    "num_epochs = 10\n",
    "alpha = 0.001\n",
    "\n",
    "# create a model\n",
    "model = Autoencoder()\n",
    "\n",
    "# define loss-function and optimizer\n",
    "cross_entropy_loss = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# create empty arrays to store test/accuracy values, to track the network progress\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "#test_accuracies = []\n",
    "\n",
    "# get initial accuracy- and loss valus before training starts\n",
    "test_loss= test(model, test_ds_noisy, cross_entropy_loss)\n",
    "test_losses.append(test_loss)\n",
    "#test_accuracies.append(test_accuracy)\n",
    "\n",
    "train_loss= test(model, train_ds_noisy, cross_entropy_loss)\n",
    "train_losses.append(train_loss)\n",
    "\n",
    "print(\"Starting Training ResNet: \")\n",
    "# training loop\n",
    "average_time = []\n",
    "for epoch in range(num_epochs):\n",
    "    # print accuracy of each epoch\n",
    "    pre_train_time = time.time()\n",
    "   # print(f'Epoch: {str(epoch)} starting with accuracy {str(test_accuracies[-1])}')\n",
    "    \n",
    "    loss_epoch = []\n",
    "    # for all input, do a forwardstep and obtain loss\n",
    "    for input, target in tqdm(train_ds_noisy):\n",
    "        train_loss = train_step(model, input, target, cross_entropy_loss, optimizer)\n",
    "        loss_epoch.append(train_loss)\n",
    "    # get the mean loss of this epoch by using reduce_sum of TF over all input-losses and appending to the array  \n",
    "    train_losses.append(tf.reduce_mean(loss_epoch))\n",
    "    \n",
    "    # get the losses and accuracy of this epoch and store them\n",
    "    test_loss = test(model, test_ds_noisy, cross_entropy_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    #test_accuracies.append(test_accuracy)\n",
    "\n",
    "    average_time.append(time.time() - pre_train_time)\n",
    "    print(\"Took: \" + str(time.time() - pre_train_time))\n",
    "    print(\"Loss for this epoch: \" + str(test_loss))\n",
    "    \n",
    "# print accuracy after 10 epochs\n",
    "#rint(test_accuracies[-1])\n",
    "print(\"Mean Time per Epoch: \" + str(round(np.mean(average_time), 2)) + \"! With Parameters: \")\n",
    "\n",
    "print(\"Batch size: \" + str(BATCH_SIZE) + \"  Prefetch size: \" + str(PREFETCH_SIZE) + \"  Buffer size: \" + str(BUFFER_SIZE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "line1, = plt.plot(train_losses)\n",
    "line2, = plt.plot(test_losses)\n",
    "#line3, = plt.plot(test_accuracies)\n",
    "plt.xlabel(\"Training steps\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend((line1,line2),(\"training\",\"test\"))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f2ce5b025ee46dfd59c93f3793a6f842c4d262f1d9a3727dc60bd3e533930326"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('tf_m1': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
