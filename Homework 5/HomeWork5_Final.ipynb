{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a75fce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679e4319",
   "metadata": {},
   "source": [
    "Load Dataset from Tensorflow Datasets and split into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f423d5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds = tfds.load('fashion_mnist', split=['train', 'test'], as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5df881ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "PREFETCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298e29cb",
   "metadata": {},
   "source": [
    "Dataset Pipeline Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5789c822",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-4ff4de58404b>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-4ff4de58404b>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    data = data.filter( if(data[1] == 5): return False else: True)\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def prepare_fashion_dataset(data):\n",
    "    \n",
    "    data = data.map(lambda img, target: (tf.cast(img, tf.float32), target))\n",
    "    # normalize inputs from 0/255 to -1/1\n",
    "    data = data.map(lambda img, target: ((img/128.)-1, target))\n",
    "    # create one-hot vector for targets\n",
    "    data = data.map(lambda img, target: (img, tf.one_hot(target, depth=10)))\n",
    "\n",
    "    data = data.filter( data[1] == 5): return False else: True)\n",
    "    # cache, shuffle, batch and prefetch data for efficient processing \n",
    "    data = data.cache()\n",
    "    data = data.shuffle(1000).batch(BATCH_SIZE).prefetch(PREFETCH_SIZE)\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "607ce270",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "in user code:\n\n    File \"<ipython-input-6-3f77635b4a97>\", line 9, in None  *\n        lambda img, target: bool(target < 5)\n\n    OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-5de562c8f12a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_ds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_fashion_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_ds\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mprepare_fashion_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# train_ds = train_ds.apply(prepare_fashion_dataset)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# test_ds =  test_ds.apply(prepare_fashion_dataset)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-3f77635b4a97>\u001b[0m in \u001b[0;36mprepare_fashion_dataset\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;31m# cache, shuffle, batch and prefetch data for efficient processing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(self, predicate, name)\u001b[0m\n\u001b[0;32m   2200\u001b[0m           \u001b[0;31m`\u001b[0m\u001b[0mpredicate\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2201\u001b[0m     \"\"\"\n\u001b[1;32m-> 2202\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mFilterDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2204\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformation_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, predicate, use_legacy_function, name)\u001b[0m\n\u001b[0;32m   5712\u001b[0m     \u001b[1;34m\"\"\"See `Dataset.filter()` for details.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5713\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5714\u001b[1;33m     wrapped_func = StructuredFunctionWrapper(\n\u001b[0m\u001b[0;32m   5715\u001b[0m         \u001b[0mpredicate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5716\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m   4531\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4533\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4534\u001b[0m     \u001b[1;31m# There is no graph to add in eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4535\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[1;33m&=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3242\u001b[0m          \u001b[1;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3243\u001b[0m     \"\"\"\n\u001b[1;32m-> 3244\u001b[1;33m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[0;32m   3245\u001b[0m         *args, **kwargs)\n\u001b[0;32m   3246\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3208\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3209\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3210\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3211\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3556\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3557\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3558\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3390\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3391\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3392\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3393\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3394\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1141\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1143\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   4508\u001b[0m           attributes=defun_kwargs)\n\u001b[0;32m   4509\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=missing-docstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4510\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4511\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4512\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   4438\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4439\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4440\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4441\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4442\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    697\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperatorNotAllowedInGraphError\u001b[0m: in user code:\n\n    File \"<ipython-input-6-3f77635b4a97>\", line 9, in None  *\n        lambda img, target: bool(target < 5)\n\n    OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.\n"
     ]
    }
   ],
   "source": [
    "train_ds = prepare_fashion_dataset(train_ds)\n",
    "test_ds =  prepare_fashion_dataset(test_ds)\n",
    "\n",
    "# train_ds = train_ds.apply(prepare_fashion_dataset)\n",
    "# test_ds =  test_ds.apply(prepare_fashion_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0302f62",
   "metadata": {},
   "source": [
    "Construct a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0e051384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom model with custom layer\n",
    "class CustomModel(tf.keras.Model):\n",
    "    \n",
    "    # Instantiate layer \n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        # Apply 24 kernel filters to our input\n",
    "        # Convert from (28x28x1) to (28x28x24)\n",
    "        self.conv1 = Conv2D(filters = 24, kernel_size = 3, padding = \"same\", activation = \"relu\")\n",
    "        self.conv2 = Conv2D(filters = 24, kernel_size = 3, padding = \"same\", activation = \"relu\")\n",
    "        # Cut the size by half and only keep most prominent values (reduce noise)\n",
    "        # Convert (28x28x24) to (14x14x24)\n",
    "        self.pooling = MaxPooling2D(pool_size = 2, strides = 2)\n",
    "        # Apply 48 kernel filters\n",
    "        # Convert from (14x14x24) to (14x14x48)\n",
    "        self.conv3 = Conv2D(filters = 48, kernel_size = 3, padding = \"same\", activation = \"relu\")\n",
    "        self.conv4 = Conv2D(filters = 48, kernel_size = 3, padding = \"same\", activation = \"relu\")\n",
    "        # Take the mean of each of the 48 matrices\n",
    "        # Convert output to (1x48)\n",
    "        self.global_pool = GlobalAveragePooling2D()\n",
    "        # Convert to (1x10) outputs\n",
    "        self.out = Dense(10, activation = 'softmax')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # cast the call-function as tf.function to increase efficiency\n",
    "    @tf.function\n",
    "    # pass the input through the layers of the network and return the output\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pooling(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987a1b61",
   "metadata": {},
   "source": [
    "Training Step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "544cd484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, input, target, loss_function, optimizer):\n",
    "  # Keeps track of gradients\n",
    "  with tf.GradientTape() as tape:\n",
    "    prediction = model(input)\n",
    "    loss = loss_function(target, prediction)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  \n",
    "  # Reduce weights by gradients with selected optimizer\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08cfb4f",
   "metadata": {},
   "source": [
    "Testing Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "27d17e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_data, loss_function):\n",
    "  # test over complete test data\n",
    "\n",
    "  test_accuracy_aggregator = []\n",
    "  test_loss_aggregator = []\n",
    "\n",
    "  for (input, target) in test_data:\n",
    "    # Calculate output and loss\n",
    "    prediction = model(input)\n",
    "    sample_test_loss = loss_function(target, prediction)\n",
    "    # Check wether index of network output and the target for True is the same\n",
    "    sample_test_accuracy =  np.argmax(target, axis=1) == np.argmax(prediction, axis=1)\n",
    "    # Take the mean over the whole dataset => accuracy of 1 epoch\n",
    "    sample_test_accuracy = np.mean(sample_test_accuracy)\n",
    "    # Keep track of accuracy and loss\n",
    "    test_loss_aggregator.append(sample_test_loss.numpy())\n",
    "    test_accuracy_aggregator.append(np.mean(sample_test_accuracy))\n",
    "\n",
    "  test_loss = tf.reduce_mean(test_loss_aggregator)\n",
    "  test_accuracy = tf.reduce_mean(test_accuracy_aggregator)\n",
    "\n",
    "  return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4f5e0b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0f3996",
   "metadata": {},
   "source": [
    "Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5ec0ed63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 starting with accuracy 0.09994009584664537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:17<00:00, 110.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs Loss: 0.7730628848075867\n",
      "Epoch took: 17.956351280212402\n",
      "Epoch: 1 starting with accuracy 0.6936900958466453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:16<00:00, 110.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs Loss: 0.5425678491592407\n",
      "Epoch took: 17.850286960601807\n",
      "Epoch: 2 starting with accuracy 0.8031150159744409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:17<00:00, 109.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs Loss: 0.5313573479652405\n",
      "Epoch took: 17.977550268173218\n",
      "Epoch: 3 starting with accuracy 0.8067092651757188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:17<00:00, 107.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs Loss: 0.46020424365997314\n",
      "Epoch took: 18.339478015899658\n",
      "Epoch: 4 starting with accuracy 0.8369608626198083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:17<00:00, 110.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs Loss: 0.41129767894744873\n",
      "Epoch took: 17.951887369155884\n",
      "Epoch: 5 starting with accuracy 0.8614217252396166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:17<00:00, 105.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs Loss: 0.3851105570793152\n",
      "Epoch took: 18.559653759002686\n",
      "Epoch: 6 starting with accuracy 0.863917731629393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:16<00:00, 110.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs Loss: 0.3725435435771942\n",
      "Epoch took: 17.936398029327393\n",
      "Epoch: 7 starting with accuracy 0.8729033546325878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:16<00:00, 113.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs Loss: 0.3561350107192993\n",
      "Epoch took: 17.510416269302368\n",
      "Epoch: 8 starting with accuracy 0.8741014376996805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:17<00:00, 106.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs Loss: 0.3316086232662201\n",
      "Epoch took: 18.570767641067505\n",
      "Epoch: 9 starting with accuracy 0.8825878594249201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:14<00:00, 131.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs Loss: 0.3557920753955841\n",
      "Epoch took: 15.099632263183594\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "learning_rate = 0.05\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "model = CustomModel()\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the loss: categorical cross entropy. Check out 'tf.keras.losses'.\n",
    "cross_entropy_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "# Initialize the optimizer: SGD with default parameters. Check out 'tf.keras.optimizers'\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize lists for later visualization.\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "#testing once before we begin\n",
    "test_loss, test_accuracy = test(model, test_ds, cross_entropy_loss)\n",
    "test_losses.append(test_loss)\n",
    "test_accuracies.append(test_accuracy)\n",
    "\n",
    "#check how model performs on train data once before we begin\n",
    "train_loss, _ = test(model, train_ds, cross_entropy_loss)\n",
    "train_losses.append(train_loss)\n",
    "\n",
    "\n",
    "# We train for num_epochs epochs.\n",
    "for epoch in range(num_epochs):\n",
    "    current_time  = time.time()\n",
    "    print(f'Epoch: {str(epoch)} starting with accuracy {test_accuracies[-1]}')\n",
    "\n",
    "    #training (and checking in with training)\n",
    "    epoch_loss_agg = []\n",
    "    for input,target in tqdm(train_ds):\n",
    "        train_loss = train_step(model, input, target, cross_entropy_loss, optimizer)\n",
    "        epoch_loss_agg.append(train_loss)\n",
    "    \n",
    "    #track training loss\n",
    "    train_losses.append(tf.reduce_mean(epoch_loss_agg))\n",
    "\n",
    "    #testing, so we can track accuracy and test loss\n",
    "    test_loss, test_accuracy = test(model, test_ds, cross_entropy_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    print(f'Epochs Loss: {test_losses[-1]}')\n",
    "    print(f'Epoch took: {str(time.time()-current_time)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "127f5510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Visualize accuracy and loss for training and test data.\n",
    "plt.figure()\n",
    "line1, = plt.plot(train_losses)\n",
    "line2, = plt.plot(test_losses)\n",
    "line3, = plt.plot(test_accuracies)\n",
    "plt.xlabel(\"Training steps\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend((line1,line2, line3),(\"training\",\"test\", \"test accuracy\"))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4f1073c099ddc7feaa79a7ad20594747d23b588351da1e73dea2959a263903ad"
  },
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
