{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9484023",
   "metadata": {},
   "source": [
    "Homework 3 Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f5ce3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d17367f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Stuff\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "#loading the genomics data_set from tfds\n",
    "train_ds, test_ds = tfds.load('genomics_ood', split=['train','test'], as_supervised=True)\n",
    "\n",
    "#genomics_ds, info = tfds.load('genomics_ood', split='train', with_info=True, as_supervised=True)\n",
    "#print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a0267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a onehot vector by substiting and \n",
    "def onehotify(tensor):\n",
    "    vocab = {'A': '1', 'C': '2', 'G': '3', 'T': '4'}\n",
    "    for key in vocab.keys():\n",
    "        tensor = tf.strings.regex_replace(tensor, key, vocab[key]) \n",
    "    split = tf.strings.bytes_split(tensor)\n",
    "    labels = tf.cast(tf.strings.to_number(split), tf.uint8) \n",
    "    onehot = tf.one_hot(labels, 4)\n",
    "    onehot = tf.reshape(onehot, (-1,))\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12076bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean dataset, so labels and vectors are depicted as One-Hot-Tensors\n",
    "def clean_dataset(g):\n",
    "    # use the pre-defined function to replace Strings by Int-values\n",
    "    g = g.map(lambda seq, label: (onehotify(seq), label)) \n",
    "    # convert the labels to one_hot_tensor\n",
    "    g = g.map(lambda seq, label: (seq, tf.one_hot(label, depth=10))) \n",
    "    # return cleaned data\n",
    "    return g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b11d61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom layer\n",
    "\n",
    "class CustomLayer(tf.keras.layers.Layer):\n",
    "    # init func with customizable size and activation function, standard units=8, Activation = sigmoid\n",
    "    def __init__(self, units=8, activation=tf.nn.sigmoid):\n",
    "        super(CustomLayer, self).__init__()\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "        \n",
    "    # build function to apply shape of input to layer when build, creating according weights and biases \n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                initializer='random_normal',\n",
    "                                trainable=True)\n",
    "\n",
    "        self.b = self.add_weight(shape=(self.units,), \n",
    "                              initializer='random_normal',\n",
    "                              trainable=True)\n",
    "    # when called return neuron output/drive by multiplying input with weights + bias and applying the activation function\n",
    "    def call(self, inputs):\n",
    "        x = tf.matmul(inputs, self.w) + self.b\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f436239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom model with custom layer\n",
    "class CustomModel(tf.keras.Model):\n",
    "    \n",
    "    # init our model with 2 hidden layers of 256 Units and sigmoid activation and one output layer with softmax activation\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.layer1 = CustomLayer(256) # sigmoid is standard\n",
    "        self.layer2 = CustomLayer(256)\n",
    "        self.out = CustomLayer(10, tf.nn.softmax)\n",
    "    \n",
    "    # cast the call-function as tf.function to increase efficiency\n",
    "    @tf.function\n",
    "    # pass the input through the layers of the network and return the output\n",
    "    def call(self, inputs):\n",
    "        x = self.layer1(inputs)\n",
    "        x = self.layer2(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5915d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the loss of an input for the model and optimize/tweak according the parameters\n",
    "def train_step(model, input, target, loss_function, optimizer):\n",
    "    # use tf.gradientTape to compute loss, then gradients and apply these to the model to modify the parameters\n",
    "    with tf.GradientTape() as tape:\n",
    "        prediction = model(input)\n",
    "        loss = loss_function(target, prediction)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "\n",
    "# compute the differences between or model prediction and the label, -> Supervision\n",
    "def test(model, test_data, loss_function):\n",
    "  # test over complete test data\n",
    "  test_accuracy_aggregator = []\n",
    "  test_loss_aggregator = []\n",
    "\n",
    "  for (input, target) in test_data:\n",
    "    prediction = model(input)\n",
    "    sample_test_loss = loss_function(target, prediction)\n",
    "    sample_test_accuracy =  np.argmax(target, axis=1) == np.argmax(prediction, axis=1)\n",
    "    sample_test_accuracy = np.mean(sample_test_accuracy)\n",
    "    test_loss_aggregator.append(sample_test_loss.numpy())\n",
    "    test_accuracy_aggregator.append(np.mean(sample_test_accuracy))\n",
    "    \n",
    "# for all input and computed losses get the mean of accuracy and loss and return them\n",
    "  test_loss = tf.reduce_mean(test_loss_aggregator)\n",
    "  test_accuracy = tf.reduce_mean(test_accuracy_aggregator)\n",
    "\n",
    "  return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a38e857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear any leftover computations of the TF Background\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3208cdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function clean_dataset.<locals>.<lambda> at 0x147503dc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Assign: 2, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function clean_dataset.<locals>.<lambda> at 0x147503dc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Assign: 2, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function clean_dataset.<locals>.<lambda> at 0x147503dc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Assign: 2, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function clean_dataset.<locals>.<lambda> at 0x14763d310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Assign: 2, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function clean_dataset.<locals>.<lambda> at 0x14763d310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Assign: 2, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function clean_dataset.<locals>.<lambda> at 0x14763d310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Assign: 2, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function clean_dataset.<locals>.<lambda> at 0x147503c10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Assign: 2, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function clean_dataset.<locals>.<lambda> at 0x147503c10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Assign: 2, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function clean_dataset.<locals>.<lambda> at 0x147503c10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Assign: 2, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function clean_dataset.<locals>.<lambda> at 0x1475ea1f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Assign: 2, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function clean_dataset.<locals>.<lambda> at 0x1475ea1f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Assign: 2, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function clean_dataset.<locals>.<lambda> at 0x1475ea1f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Assign: 2, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-14 16:58:16.453210: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-11-14 16:58:16.454004: W tensorflow/core/platform/profile_utils/cpu_utils.cc:126] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 starting with accuracy tf.Tensor(0.096, shape=(), dtype=float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-14 16:58:33.801601: W tensorflow/core/framework/op_kernel.cc:1775] OP_REQUIRES failed at mlc_matmul_ops.cc:136 : Internal: TransposeMLCBytes: Input bytes is nullptr.\n",
      "2021-11-14 16:58:33.803105: W tensorflow/core/framework/op_kernel.cc:1775] OP_REQUIRES failed at mlc_matmul_ops.cc:207 : Aborted: Compute: Operation received an exception: Compute: No MLCTrainingGraph has been found.\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": " TransposeMLCBytes: Input bytes is nullptr.\n\t [[node gradients/custom_layer_2/MatMul_grad/MLCMatMul_1 (defined at Users/noomin/miniforge3/envs/tf_m1/lib/python3.8/site-packages/tensorflow/compiler/tf2mlcompute/ops/gen_mlc_ops.py:5535) ]] [Op:__inference___backward_call_3593_3629]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradients/custom_layer_2/MatMul_grad/MLCMatMul_1:\n gradients/custom_layer_2/add_grad/MLCAddGrad (defined at Users/noomin/miniforge3/envs/tf_m1/lib/python3.8/site-packages/tensorflow/compiler/tf2mlcompute/ops/gen_mlc_ops.py:304)\n\nFunction call stack:\n__backward_call_3593\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bd/0dfykvgs4mscqmxf9r8jmtcm0000gp/T/ipykernel_88508/2893551359.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# for all input, do a forwardstep and obtain loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mloss_epoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# get the mean loss of this epoch by using reduce_sum of TF over all input-losses and appending to the array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/bd/0dfykvgs4mscqmxf9r8jmtcm0000gp/T/ipykernel_88508/3767933988.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, input, target, loss_function, optimizer)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_m1/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1078\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1080\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1081\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_m1/lib/python3.8/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     72\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_m1/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_backward_function_wrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   1281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_index\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mbackward_function_inputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m           \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m       return backward._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   1284\u001b[0m           processed_args, remapped_captures)\n\u001b[1;32m   1285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_m1/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniforge3/envs/tf_m1/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_m1/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m:  TransposeMLCBytes: Input bytes is nullptr.\n\t [[node gradients/custom_layer_2/MatMul_grad/MLCMatMul_1 (defined at Users/noomin/miniforge3/envs/tf_m1/lib/python3.8/site-packages/tensorflow/compiler/tf2mlcompute/ops/gen_mlc_ops.py:5535) ]] [Op:__inference___backward_call_3593_3629]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradients/custom_layer_2/MatMul_grad/MLCMatMul_1:\n gradients/custom_layer_2/add_grad/MLCAddGrad (defined at Users/noomin/miniforge3/envs/tf_m1/lib/python3.8/site-packages/tensorflow/compiler/tf2mlcompute/ops/gen_mlc_ops.py:304)\n\nFunction call stack:\n__backward_call_3593\n"
     ]
    }
   ],
   "source": [
    "#create clean Data-sets for Training and testing\n",
    "test_ds = test_ds.apply(clean_dataset)\n",
    "train_ds = train_ds.apply(clean_dataset)  \n",
    "\n",
    "#take a smaller amount of samples for our purposes\n",
    "test_ds = test_ds.take(1000)\n",
    "train_ds = train_ds.take(100000)\n",
    "\n",
    "#shuffle, batch and prefetch both Datasets\n",
    "train_ds = train_ds.shuffle(1000)\n",
    "train_ds = train_ds.batch(1000)\n",
    "train_ds = train_ds.prefetch(20)\n",
    "\n",
    "test_ds = test_ds.shuffle(1000)\n",
    "test_ds = test_ds.batch(1000)\n",
    "test_ds = test_ds.prefetch(20)\n",
    "\n",
    "#predefine learning-rate and epochs\n",
    "num_epochs = 10\n",
    "alpha = 0.1\n",
    "\n",
    "# create a model\n",
    "model = CustomModel()\n",
    "\n",
    "# define loss-function and optimizer\n",
    "cross_entropy_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.SGD(alpha)\n",
    "\n",
    "# create empty arrays to store test/accuracy values, to track the network progress\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "# get initial accuracy- and loss valus before training starts\n",
    "test_loss, test_accuracy = test(model, test_ds, cross_entropy_loss)\n",
    "test_losses.append(test_loss)\n",
    "test_accuracies.append(test_accuracy)\n",
    "\n",
    "train_loss, _ = test(model, train_ds, cross_entropy_loss)\n",
    "train_losses.append(train_loss)\n",
    "\n",
    "\n",
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # print accuracy of each epoch\n",
    "    print(f'Epoch: {str(epoch)} starting with accuracy {str(test_accuracies[-1])}')\n",
    "    \n",
    "    loss_epoch = []\n",
    "    # for all input, do a forwardstep and obtain loss\n",
    "    for input, target in train_ds:\n",
    "        train_loss = train_step(model, input, target, cross_entropy_loss, optimizer)\n",
    "        loss_epoch.append(train_loss)\n",
    "    # get the mean loss of this epoch by using reduce_sum of TF over all input-losses and appending to the array  \n",
    "    train_losses.append(tf.reduce_mean(loss_epoch))\n",
    "    \n",
    "    # get the losses and accuracy of this epoch and store them\n",
    "    test_loss, test_accuracy = test(model, test_ds, cross_entropy_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    \n",
    "# print accuracy after 10 epochs\n",
    "print(test_accuracies[-1])\n",
    "          \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0151b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the values stored over training and test time with pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "line1, = plt.plot(train_losses)\n",
    "line2, = plt.plot(test_losses)\n",
    "line3, = plt.plot(test_accuracies)\n",
    "plt.xlabel(\"Training steps\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend((line1,line2,line3),(\"training\",\"test\", \"accuracy\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbbbf74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
