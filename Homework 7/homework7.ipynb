{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "#VERBOSE = True\n",
    "SHUFFLE_SIZE = 1000\n",
    "BATCH_SIZE = 64\n",
    "PREFETCH_SIZE = 128\n",
    "BUFFER_SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise Range between -2 and 2 --> Return tensor with length seq_len\n",
    "# Target if integral\n",
    "def integration_task(seq_len, num_samples, r = 2):\n",
    "    for i in range(num_samples):\n",
    "        noise_sample = []\n",
    "        for j in range(seq_len):\n",
    "            noise_sample.append(random.uniform(-r, r))\n",
    "        target = np.trapz(noise_sample)\n",
    "        if target < 0: target = -1\n",
    "        else: target = 1\n",
    "        yield noise_sample, target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_gen = integration_task(seq_len = 10, num_samples = 3, r = 2)\n",
    "noise_func1, noise_target1 = next(noise_gen)\n",
    "noise_func2, noise_target2 = next(noise_gen)\n",
    "noise_func3, noise_target3 = next(noise_gen)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# line0, = plt.plot(np.zeros_like(noise_func1))\n",
    "# line1, = plt.plot(noise_func1)\n",
    "# line2, = plt.plot(noise_func2)\n",
    "# line3, = plt.plot(noise_func3)\n",
    "# plt.xlabel(\"Time (t)\")\n",
    "# plt.ylabel(\"White Noise\")\n",
    "# plt.legend((line1,line2,line3),(str(noise_target1), str(noise_target2), str(noise_target3)))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapper Function for integration task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_integration_task():\n",
    "    SEQ_LENGTH = 10\n",
    "    NUM_SAMPLES = 10\n",
    "\n",
    "    for i in range(len(list(integration_task(SEQ_LENGTH, NUM_SAMPLES)))):\n",
    "        yield next(integration_task(SEQ_LENGTH, NUM_SAMPLES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "integration = my_integration_task()\n",
    "verbose = False\n",
    "while next(integration) and verbose:\n",
    "    print(next(integration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FlatMapDataset' object has no attribute 'd'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3100/1076378200.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_integration_task\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'FlatMapDataset' object has no attribute 'd'"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_generator(my_integration_task, output_signature = tf.TensorSpec(shape = (25,1), dtype = tf.float32))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    # Shuffle, batch and prefetch\n",
    "    data = data.shuffle(SHUFFLE_SIZE).batch(BATCH_SIZE).prefetch(PREFETCH_SIZE)\n",
    "    return data\n",
    "    \n",
    "\n",
    "dataset = preprocess(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Cell(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LSTM_Cell, self).__init__()\n",
    "\n",
    "        # Forget Gate\n",
    "        self.f_gate = Dense(32, activation=\"sigmoid\", bias_initializer=initializers.Constant(0.1))\n",
    "\n",
    "        # Input Gate\n",
    "        self.inp_filter = Dense(32, activation=\"sigmoid\")\n",
    "        self.selecter = Dense(32, activation=\"tanh\")\n",
    "\n",
    "        # Output Gate\n",
    "        self.out_filter = Dense(32, activation=\"sigmoid\")\n",
    "\n",
    "\n",
    "    # Pass input through network\n",
    "\n",
    "    # cast the call-function as tf.function to increase efficiency\n",
    "    #@tf.function\n",
    "    def call(self, x, states):\n",
    "\n",
    "        # Concat input and hidden state h(t-1)\n",
    "        self.x = tf.keras.layers.Concatenate()([x, states[0]])\n",
    "\n",
    "        # Forget Gate\n",
    "        # \"Delete\" some elements of old cell by multiplying with element between 0-1\n",
    "        states[1] = tf.math.multiply(states[1], self.f_gate(self.x))\n",
    "\n",
    "        # statesut Gate\n",
    "        # Add some parts of our statesut to cell state (LTM)\n",
    "        states[1] += tf.math.multiply(self.inp_filter(self.x), self.selecter(self.x))\n",
    "\n",
    "        # Output Gate\n",
    "        # Combine information from cell- and hidden state\n",
    "        self.out = tf.math.multiply(self.out_filter(self.x), tf.keras.activations.tanh(states[1]))\n",
    "\n",
    "        # [Output/hidden state, updated cell state]\n",
    "        return([self.out, states[1]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f2ce5b025ee46dfd59c93f3793a6f842c4d262f1d9a3727dc60bd3e533930326"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('tf_m1': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
