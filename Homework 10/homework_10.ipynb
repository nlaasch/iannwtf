{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text\n",
    "import random\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import re\n",
    "from tensorflow.keras.layers import Layer, Embedding, Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bible.txt', 'r') as file:\n",
    "    bible = file.read().replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(text,k = 10000, splitter = \"whitespace\", with_dot = False):\n",
    "    p = text.lower()\n",
    "    \n",
    "    if(with_dot):\n",
    "        p = re.sub('[^A-Za-z. ]+', '', p)\n",
    "    else: \n",
    "        p = re.sub('[^A-Za-z ]+', '', p)\n",
    "    \n",
    "    split_it = p.split()\n",
    "    counter = Counter(split_it)\n",
    "    most_occur = counter.most_common(k)\n",
    "\n",
    "    p = ' '.join(p.split())\n",
    "\n",
    "    if splitter == \"whitespace\":\n",
    "        splitter = tf_text.WhitespaceTokenizer()\n",
    "        p = splitter.split(p)  \n",
    "\n",
    "\n",
    "    return p, split_it, most_occur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbible, ogbible, most_occur = prep(bible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'the' b'first' b'book' ... b'you' b'all' b'amen'], shape=(790017,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print(pbible)\n",
    "#print(type(ogbible))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexer(word, wlist):\n",
    "    matched_indeces = []\n",
    "    i = 0\n",
    "    length = len(wlist)\n",
    "    while i < length:\n",
    "        if word == wlist[i]:\n",
    "            matched_indeces.append(i)\n",
    "        i += 1\n",
    "    return matched_indeces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to build pairs\n",
    "def find_context(word, bible, k = 4):\n",
    "    scope = []\n",
    "    indexes = indexer(word, bible)\n",
    "    index = indexes[random.randint(0, len(indexes)-1)]\n",
    "    for i in range(int(k/2)):\n",
    "        scope.append((word,bible[index-(i+1)]))\n",
    "        scope.append((word,bible[index+(i+1)]))\n",
    "    return scope[random.randint(0, k-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:29<00:00, 11.21it/s]\n"
     ]
    }
   ],
   "source": [
    "def create_dataset(bible, mocc, k = 1000):\n",
    "    \n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for i in tqdm(range(k)):\n",
    "        inputs.append(find_context(mocc[i][0], bible)[0])\n",
    "        targets.append(find_context(mocc[i][0], bible)[1])\n",
    "\n",
    "    return inputs, targets, list(set(inputs) | set(targets))\n",
    "\n",
    "data_in, data_target, dictionary = create_dataset(ogbible,most_occur)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(word, wdict):\n",
    "    vector = np.zeros_like(wdict, dtype = int)\n",
    "    vector[wdict.index(word)] = 1\n",
    "    return vector\n",
    "\n",
    "def unhot(vector, wdict = dictionary):\n",
    "    return wdict[list(vector).index(1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 1080), (None, 1080)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def onehot_dataset(data, wdict):\n",
    "    l = []\n",
    "    for d in data:\n",
    "        l.append(onehot(d, wdict))\n",
    "    return np.array(l)\n",
    "\n",
    "odata_in = onehot_dataset(data_in, dictionary)\n",
    "odata_out = onehot_dataset(data_target, dictionary)\n",
    "\n",
    "print(len(odata_in))\n",
    "print(len(odata_out))\n",
    "\n",
    "f_dataset = tf.data.Dataset.from_tensor_slices((odata_in, odata_out))\n",
    "f_dataset.shuffle(1000).batch(512).prefetch(512)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess to return pairs onehot encoded\n",
    "def preprocess(data):\n",
    "    data = data.map(lambda word, context: (word, tf.one_hot(context, depth=1)))\n",
    "    data = data.shuffle(1000).batch(512).prefetch(512)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"<ipython-input-72-8b0ccde5d4a5>\", line 3, in None  *\n        lambda word, context: (word, tf.one_hot(context, depth=1))\n\n    TypeError: Value passed to parameter 'indices' has DataType string not in list of allowed values: uint8, int32, int64\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-bc9299a085e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpreprocessed_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-113-493810910014>\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Preprocess to return pairs onehot encoded\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m   2002\u001b[0m         warnings.warn(\"The `deterministic` argument has no effect unless the \"\n\u001b[0;32m   2003\u001b[0m                       \"`num_parallel_calls` argument is specified.\")\n\u001b[1;32m-> 2004\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2005\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2006\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[0;32m   5453\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5454\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_preserve_cardinality\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5455\u001b[1;33m     self._map_func = StructuredFunctionWrapper(\n\u001b[0m\u001b[0;32m   5456\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5457\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m   4531\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4533\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4534\u001b[0m     \u001b[1;31m# There is no graph to add in eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4535\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[1;33m&=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3242\u001b[0m          \u001b[1;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3243\u001b[0m     \"\"\"\n\u001b[1;32m-> 3244\u001b[1;33m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[0;32m   3245\u001b[0m         *args, **kwargs)\n\u001b[0;32m   3246\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3208\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3209\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3210\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3211\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3556\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3557\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3558\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3390\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3391\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3392\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3393\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3394\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1141\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1143\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   4508\u001b[0m           attributes=defun_kwargs)\n\u001b[0;32m   4509\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=missing-docstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4510\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4511\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4512\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   4438\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4439\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4440\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4441\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4442\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    697\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"<ipython-input-72-8b0ccde5d4a5>\", line 3, in None  *\n        lambda word, context: (word, tf.one_hot(context, depth=1))\n\n    TypeError: Value passed to parameter 'indices' has DataType string not in list of allowed values: uint8, int32, int64\n"
     ]
    }
   ],
   "source": [
    "preprocessed_data = preprocess(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEmbedder(Layer):\n",
    "    def __init__(self):\n",
    "        super(CustomEmbedder, self).__init__()\n",
    "        self.embedder = Embedding(len(dictionary), 64)\n",
    "        self.classifier = Embedding(64, len(dictionary))\n",
    "        self.activation = Softmax()\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, input):\n",
    "        x = self.embedder(input)\n",
    "        x = self.classifier(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the loss of an input for the model and optimize/tweak according the parameters\n",
    "def train_step(model, input, target, loss_function, optimizer):\n",
    "    # use tf.gradientTape to compute loss, then gradients and apply these to the model to modify the parameters\n",
    "    with tf.GradientTape() as tape:\n",
    "        prediction = model(input)\n",
    "        loss = loss_function(target, prediction)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "\n",
    "# # compute the differences between or model prediction and the label, -> Supervision\n",
    "# def test(model, test_data, loss_function):\n",
    "#   # test over complete test data\n",
    "#   test_loss_aggregator = []\n",
    "#   for (input, target) in test_data:\n",
    "\n",
    "#     prediction = model(input)\n",
    "    \n",
    "#     sample_test_loss = loss_function(target, prediction)\n",
    "    \n",
    "#     test_loss_aggregator.append(sample_test_loss.numpy())\n",
    "    \n",
    "# # for all input and computed losses get the mean of accuracy and loss and return them\n",
    "#   test_loss = tf.reduce_mean(test_loss_aggregator)\n",
    "\n",
    "#   return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Skip-Gram \n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Exception encountered when calling layer \"custom_embedder_2\" (type CustomEmbedder).\n\n OOM when allocating tensor with shape[1080,64,1080] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node embedding_5/embedding_lookup\n (defined at C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\layers\\embeddings.py:191)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__forward_call_7773]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node embedding_5/embedding_lookup:\nIn[0] embedding_5/embedding_lookup/7742:\t\nIn[1] embedding_5/Cast (defined at C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\layers\\embeddings.py:190)\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelapp.py\", line 619, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\asyncio\\events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\gen.py\", line 814, in inner\n>>>     self.ctx_run(self.run)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\gen.py\", line 775, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 358, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 261, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 536, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\ipkernel.py\", line 302, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\zmqshell.py\", line 539, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2898, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2944, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3169, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-23-26d3b91d76ed>\", line 32, in <module>\n>>>     train_loss = train_step(model, input, target, cross_entropy_loss, optimizer)\n>>> \n>>>   File \"<ipython-input-18-b089d3af2300>\", line 5, in train_step\n>>>     prediction = model(input)\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"<ipython-input-20-cf1a610348d4>\", line 12, in call\n>>>     x = self.classifier(x)\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\layers\\embeddings.py\", line 191, in call\n>>>     out = tf.nn.embedding_lookup(self.embeddings, inputs)\n>>> \n\nCall arguments received:\n  • input=tf.Tensor(shape=(1080,), dtype=int32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-26d3b91d76ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m# for all input, do a forwardstep and obtain loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf_dataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mloss_epoch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# get the mean loss of this epoch by using reduce_sum of TF over all input-losses and appending to the array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-b089d3af2300>\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(model, input, target, loss_function, optimizer)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# use tf.gradientTape to compute loss, then gradients and apply these to the model to modify the parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer \"custom_embedder_2\" (type CustomEmbedder).\n\n OOM when allocating tensor with shape[1080,64,1080] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node embedding_5/embedding_lookup\n (defined at C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\layers\\embeddings.py:191)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__forward_call_7773]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node embedding_5/embedding_lookup:\nIn[0] embedding_5/embedding_lookup/7742:\t\nIn[1] embedding_5/Cast (defined at C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\layers\\embeddings.py:190)\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelapp.py\", line 619, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\asyncio\\events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\gen.py\", line 814, in inner\n>>>     self.ctx_run(self.run)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\gen.py\", line 775, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 358, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 261, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 536, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\ipkernel.py\", line 302, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\zmqshell.py\", line 539, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2898, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2944, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3169, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"C:\\Users\\nikla\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-23-26d3b91d76ed>\", line 32, in <module>\n>>>     train_loss = train_step(model, input, target, cross_entropy_loss, optimizer)\n>>> \n>>>   File \"<ipython-input-18-b089d3af2300>\", line 5, in train_step\n>>>     prediction = model(input)\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"<ipython-input-20-cf1a610348d4>\", line 12, in call\n>>>     x = self.classifier(x)\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\nikla\\.conda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\layers\\embeddings.py\", line 191, in call\n>>>     out = tf.nn.embedding_lookup(self.embeddings, inputs)\n>>> \n\nCall arguments received:\n  • input=tf.Tensor(shape=(1080,), dtype=int32)"
     ]
    }
   ],
   "source": [
    "#predefine learning-rate and epochs\n",
    "num_epochs = 10\n",
    "alpha = 0.01\n",
    "\n",
    "# create a model\n",
    "model = CustomEmbedder()\n",
    "# define loss-function and optimizer\n",
    "cross_entropy_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# create empty arrays to store test/accuracy values, to track the network progress\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# # get initial accuracy- and loss valus before training starts\n",
    "# test_loss= test(model, test_ds, cross_entropy_loss)\n",
    "# test_losses.append(test_loss)\n",
    "\n",
    "#train_loss= test(model, train_ds, cross_entropy_loss)\n",
    "#train_losses.append(train_loss)\n",
    "\n",
    "print(\"Starting Training Skip-Gram \")\n",
    "# training loop\n",
    "average_time = []\n",
    "for epoch in range(num_epochs):\n",
    "    # print accuracy of each epoch\n",
    "    pre_train_time = time.time()\n",
    "    \n",
    "    loss_epoch = []\n",
    "    # for all input, do a forwardstep and obtain loss\n",
    "    for input, target in f_dataset:\n",
    "        train_loss = train_step(model, input, target, cross_entropy_loss, optimizer)\n",
    "        loss_epoch.append(train_loss)\n",
    "    # get the mean loss of this epoch by using reduce_sum of TF over all input-losses and appending to the array  \n",
    "    train_losses.append(tf.reduce_mean(loss_epoch))\n",
    "    \n",
    "    # get the losses and accuracy of this epoch and store them\n",
    "    #test_loss = test(model, test_ds_noisy, cross_entropy_loss)\n",
    "    #test_losses.append(test_loss)\n",
    "\n",
    "    average_time.append(time.time() - pre_train_time)\n",
    "    print(\"Took: \" + str(time.time() - pre_train_time))\n",
    "    #print(\"Loss for this epoch: \" + str(test_loss))\n",
    "    \n",
    "# print accuracy after 10 epochs\n",
    "print(\"Mean Time per Epoch: \" + str(round(np.mean(average_time), 2)) + \"! With Parameters: \")\n",
    "\n",
    "#print(\"Batch size: \" + str(BATCH_SIZE) + \"  Prefetch size: \" + str(PREFETCH_SIZE) + \"  Buffer size: \" + str(BUFFER_SIZE))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " nearest neighbours according to the(cosine similarity) of each epoch\n",
    "\n",
    " 1. Calculate the cosine similarities between the whole embedding and the\n",
    "embedding of the words you want to investigate\n",
    "2. For each selected word, sort the neighbours by their distance and return\n",
    "the k-nearest ones."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e37ec667b037d87ec56a87d451ea53809bb95d77f8477e606005eed6cafb565"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('tf_m1': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
